{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scikit-Learn Classifier on Iris Data\n",
    "\n",
    "- **KNN**\n",
    "\n",
    "- **Random Forest**: http://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "dat = pd.read_csv(\"data/iris.csv\")\n",
    "dat = np.array(dat)\n",
    "print dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = dat[:, 0:4]\n",
    "label = dat[:, 4]\n",
    "\n",
    "def label_encoder(x):\n",
    "    if x == \"setosa\":\n",
    "        return 0\n",
    "    if x == \"versicolor\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "label = np.array(map(label_encoder, label))\n",
    "\n",
    "train_index = random.sample(range(50), 35) + random.sample(range(51, 100+1), 35) + random.sample(range(101, 150), 35)\n",
    "\n",
    "train_data = data[train_index]\n",
    "train_label = label[train_index]\n",
    "\n",
    "test_data = data[list(set(range(150)) - set(train_index))]\n",
    "test_label = label[list(set(range(150)) - set(train_index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5, metric=\"euclidean\")\n",
    "\n",
    "knn.fit(train_data, train_label)\n",
    "\n",
    "preds = knn.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 2 0 2 2 0 2 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2\n",
      " 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 2 0 2 2 0 2 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Accuracy: 0.977778\n"
     ]
    }
   ],
   "source": [
    "print preds\n",
    "print test_label\n",
    "\n",
    "print \"Accuracy: %g\" % (sum(preds == test_label)/float(len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95454545  0.95238095  1.          0.85714286  0.95      ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "print cross_val_score(knn, train_data, train_label, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961904761905\n",
      "9\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.94286, std: 0.02469, params: {'n_neighbors': 1, 'metric': 'euclidean'},\n",
       " mean: 0.92381, std: 0.01365, params: {'n_neighbors': 2, 'metric': 'euclidean'},\n",
       " mean: 0.94286, std: 0.02439, params: {'n_neighbors': 3, 'metric': 'euclidean'},\n",
       " mean: 0.94286, std: 0.04049, params: {'n_neighbors': 4, 'metric': 'euclidean'},\n",
       " mean: 0.94286, std: 0.02439, params: {'n_neighbors': 5, 'metric': 'euclidean'},\n",
       " mean: 0.94286, std: 0.04049, params: {'n_neighbors': 6, 'metric': 'euclidean'},\n",
       " mean: 0.95238, std: 0.03497, params: {'n_neighbors': 7, 'metric': 'euclidean'},\n",
       " mean: 0.95238, std: 0.03497, params: {'n_neighbors': 8, 'metric': 'euclidean'},\n",
       " mean: 0.96190, std: 0.02699, params: {'n_neighbors': 9, 'metric': 'euclidean'},\n",
       " mean: 0.94286, std: 0.02469, params: {'n_neighbors': 1, 'metric': 'minkowski'},\n",
       " mean: 0.92381, std: 0.01365, params: {'n_neighbors': 2, 'metric': 'minkowski'},\n",
       " mean: 0.94286, std: 0.02439, params: {'n_neighbors': 3, 'metric': 'minkowski'},\n",
       " mean: 0.94286, std: 0.04049, params: {'n_neighbors': 4, 'metric': 'minkowski'},\n",
       " mean: 0.94286, std: 0.02439, params: {'n_neighbors': 5, 'metric': 'minkowski'},\n",
       " mean: 0.94286, std: 0.04049, params: {'n_neighbors': 6, 'metric': 'minkowski'},\n",
       " mean: 0.95238, std: 0.03497, params: {'n_neighbors': 7, 'metric': 'minkowski'},\n",
       " mean: 0.95238, std: 0.03497, params: {'n_neighbors': 8, 'metric': 'minkowski'},\n",
       " mean: 0.96190, std: 0.02699, params: {'n_neighbors': 9, 'metric': 'minkowski'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Futher tune the model\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = {\"n_neighbors\": np.arange(1,10),\n",
    "         \"metric\": [\"euclidean\", \"minkowski\"]}\n",
    "\n",
    "grid = GridSearchCV(estimator=knn,\n",
    "                    param_grid=params)\n",
    "\n",
    "grid.fit(train_data, train_label)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_neighbors)\n",
    "print(grid.best_estimator_)\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Key Parameter\n",
    "- **n_jobs**: (parallel computation) If n_jobs=k then computations are partitioned into k jobs, and run on k cores of the machine. If n_jobs=-1 then all cores available on the machine are used. Note that because of inter-process communication overhead, the speedup might not be linear (i.e., using k jobs will unfortunately not be k times as fast). Significant speedup can still be achieved though when building a large number of trees, or when building a single tree requires a fair amount of time (e.g., on large datasets).\n",
    "\n",
    "- **n_estimators**:  the number of trees in the forest. The larger the better, but also the longer it will take to compute. In addition, note that results will stop getting significantly better beyond a critical number of trees.\n",
    "\n",
    "- **max_features**: the size of the random subsets of features to consider when splitting a node. The lower the greater the reduction of variance, but also the greater the increase in bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.977778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=4)\n",
    "rf.fit(train_data, train_label)\n",
    "\n",
    "preds_rf = rf.predict(test_data)\n",
    "\n",
    "print \"Random Forest Accuracy: %f\" % (sum(preds_rf == test_label)/float(len(test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09761503,  0.02508047,  0.49547878,  0.38182572])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Futher Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971428571429\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=4,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.97143, std: 0.02403, params: {'n_estimators': 1},\n",
       " mean: 0.91429, std: 0.04842, params: {'n_estimators': 2},\n",
       " mean: 0.92381, std: 0.05071, params: {'n_estimators': 3},\n",
       " mean: 0.94286, std: 0.02439, params: {'n_estimators': 4},\n",
       " mean: 0.94286, std: 0.02240, params: {'n_estimators': 5},\n",
       " mean: 0.94286, std: 0.02240, params: {'n_estimators': 6},\n",
       " mean: 0.94286, std: 0.02439, params: {'n_estimators': 7},\n",
       " mean: 0.93333, std: 0.02704, params: {'n_estimators': 8},\n",
       " mean: 0.94286, std: 0.00133, params: {'n_estimators': 9},\n",
       " mean: 0.95238, std: 0.02831, params: {'n_estimators': 10},\n",
       " mean: 0.93333, std: 0.02704, params: {'n_estimators': 11},\n",
       " mean: 0.95238, std: 0.01356, params: {'n_estimators': 12},\n",
       " mean: 0.96190, std: 0.01445, params: {'n_estimators': 13},\n",
       " mean: 0.94286, std: 0.02240, params: {'n_estimators': 14},\n",
       " mean: 0.96190, std: 0.01445, params: {'n_estimators': 15},\n",
       " mean: 0.95238, std: 0.01356, params: {'n_estimators': 16},\n",
       " mean: 0.95238, std: 0.01356, params: {'n_estimators': 17},\n",
       " mean: 0.95238, std: 0.01356, params: {'n_estimators': 18},\n",
       " mean: 0.95238, std: 0.01356, params: {'n_estimators': 19},\n",
       " mean: 0.95238, std: 0.01356, params: {'n_estimators': 20},\n",
       " mean: 0.96190, std: 0.01445, params: {'n_estimators': 21},\n",
       " mean: 0.95238, std: 0.02831, params: {'n_estimators': 22},\n",
       " mean: 0.96190, std: 0.01445, params: {'n_estimators': 23},\n",
       " mean: 0.96190, std: 0.01445, params: {'n_estimators': 24}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = {\"n_estimators\": np.arange(1,25)}\n",
    "\n",
    "grid = GridSearchCV(estimator=rf,\n",
    "                    param_grid=params)\n",
    "\n",
    "grid.fit(train_data, train_label)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "grid.grid_scores_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
