{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage of Scikit-Learn\n",
    "\n",
    "https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf\n",
    "\n",
    "**`Scikit-learn`** is an open souorce Python library that implements a range of machine learning, preprocessing, cross-validation and visualization algorithms using a unified interface.\n",
    "\n",
    "## A Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "temp = iris.values()\n",
    "print temp[0]  # name of response variables (target)\n",
    "print temp[1][0:10, :]  # Data (features)\n",
    "print temp[2]  # encoded response variables\n",
    "# print temp[3]  # Data description\n",
    "# print temp[4]  # Feature description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2) (150,)\n",
      "(112, 2) (38, 2) (112,) (38,)\n"
     ]
    }
   ],
   "source": [
    "X, y = iris.data[:, :2], iris.target\n",
    "print X.shape, y.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 30) # random_state can be considered as random seed. It can also be left blank.\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalar = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scalar.transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.736842105263\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "print accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Instead of return the classification result, we can also return the probability of each output\n",
    "y_pred_prob = knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Data\n",
    "\n",
    "The data needs to be numeric and stored as Numpy arrays or Scipy sparse matrices. Other types that are convertible to numeric arrays, such as Pandas DataFrame, are also acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17134802  0.22462157  0.44050492  0.68326507  0.8390625 ]\n",
      " [ 0.09041675  0.78553353  0.85010276  0.68786752  0.31374997]\n",
      " [ 0.97757077  0.00476906  0.06231877  0.69363695  0.69922874]\n",
      " [ 0.17047891  0.26793686  0.28450069  0.57112648  0.57598971]\n",
      " [ 0.21950791  0.06817814  0.35457108  0.52152105  0.60964858]\n",
      " [ 0.4693126   0.2515859   0.8000239   0.86039339  0.73899714]\n",
      " [ 0.01635587  0.2425772   0.76009782  0.7865069   0.11531259]\n",
      " [ 0.30902788  0.42191159  0.12330329  0.66787937  0.89097667]\n",
      " [ 0.910608    0.83239223  0.97092464  0.70809331  0.84331188]\n",
      " [ 0.7157078   0.57836015  0.37578307  0.60287134  0.88371438]]\n",
      "[[ 0.          0.          0.          0.          0.8390625 ]\n",
      " [ 0.          0.78553353  0.85010276  0.          0.        ]\n",
      " [ 0.97757077  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.8000239   0.86039339  0.73899714]\n",
      " [ 0.          0.          0.76009782  0.7865069   0.        ]\n",
      " [ 0.          0.          0.          0.          0.89097667]\n",
      " [ 0.910608    0.83239223  0.97092464  0.70809331  0.84331188]\n",
      " [ 0.7157078   0.          0.          0.          0.88371438]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((10, 5))\n",
    "print X\n",
    "\n",
    "# or\n",
    "# X_1 = np.random.randn(10, 5)\n",
    "# print X_1\n",
    "\n",
    "y = np.array(['M','M','F','F','M','F','M','M','F','F'])\n",
    "\n",
    "X[X<0.7] = 0\n",
    "print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7157078   0.          0.          0.          0.88371438]\n",
      " [ 0.          0.78553353  0.85010276  0.          0.        ]\n",
      " [ 0.          0.          0.76009782  0.7865069   0.        ]\n",
      " [ 0.          0.          0.          0.          0.89097667]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.8390625 ]\n",
      " [ 0.          0.          0.8000239   0.86039339  0.73899714]]\n",
      "[[ 0.97757077  0.          0.          0.          0.        ]\n",
      " [ 0.910608    0.83239223  0.97092464  0.70809331  0.84331188]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "['F' 'M' 'M' 'M' 'F' 'M' 'F']\n",
      "['F' 'F' 'M']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "print X_train\n",
    "print X_test\n",
    "print y_train\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7157078   0.          0.          0.          0.88371438]\n",
      " [ 0.          0.78553353  0.85010276  0.          0.        ]\n",
      " [ 0.          0.          0.76009782  0.7865069   0.        ]\n",
      " [ 0.          0.          0.          0.          0.89097667]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.8390625 ]\n",
      " [ 0.          0.          0.8000239   0.86039339  0.73899714]]\n",
      "[[ 2.44948974 -0.40824829 -0.86443799 -0.63156632  0.96988195]\n",
      " [-0.40824829  2.44948974  1.2698146  -0.63156632 -1.14771814]\n",
      " [-0.40824829 -0.40824829  1.04384983  1.47974477 -1.14771814]\n",
      " [-0.40824829 -0.40824829 -0.86443799 -0.63156632  0.98728421]\n",
      " [-0.40824829 -0.40824829 -0.86443799 -0.63156632 -1.14771814]\n",
      " [-0.40824829 -0.40824829 -0.86443799 -0.63156632  0.8628849 ]\n",
      " [-0.40824829 -0.40824829  1.14408752  1.67808681  0.62310334]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler().fit(X_train)\n",
    "standardized_X = scalar.transform(X_train)\n",
    "standardized_X_test = scalar.transform(X_test)\n",
    "\n",
    "print X_train\n",
    "print standardized_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7157078   0.          0.          0.          0.88371438]\n",
      " [ 0.          0.78553353  0.85010276  0.          0.        ]\n",
      " [ 0.          0.          0.76009782  0.7865069   0.        ]\n",
      " [ 0.          0.          0.          0.          0.89097667]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.8390625 ]\n",
      " [ 0.          0.          0.8000239   0.86039339  0.73899714]]\n",
      "[[ 0.62936819  0.          0.          0.          0.77710725]\n",
      " [ 0.          0.67866406  0.73444884  0.          0.        ]\n",
      " [ 0.          0.          0.69493126  0.71907617  0.        ]\n",
      " [ 0.          0.          0.          0.          1.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          1.        ]\n",
      " [ 0.          0.          0.57640288  0.61989802  0.53243419]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "scalar = Normalizer().fit(X_train)\n",
    "normalized_X = scalar.transform(X_train)\n",
    "normalized_X_test = scalar.transform(X_test)\n",
    "\n",
    "print X_train\n",
    "print normalized_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7157078   0.          0.          0.          0.88371438]\n",
      " [ 0.          0.78553353  0.85010276  0.          0.        ]\n",
      " [ 0.          0.          0.76009782  0.7865069   0.        ]\n",
      " [ 0.          0.          0.          0.          0.89097667]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.8390625 ]\n",
      " [ 0.          0.          0.8000239   0.86039339  0.73899714]]\n",
      "[[ 1.  0.  0.  0.  1.]\n",
      " [ 0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "binarizer = Binarizer(threshold = 0.0).fit(X_train)\n",
    "binary_X = binarizer.transform(X_train)\n",
    "print X_train\n",
    "print binary_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize Target Variables (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'b', 'c', 'a', 'b']\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "temp_test_y = [\"a\", \"a\", \"b\", \"c\", \"a\", \"b\"]\n",
    "temp_test_y_binarized = label_binarize(temp_test_y, classes=['a','b','c'])\n",
    "print temp_test_y\n",
    "print temp_test_y_binarized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'M' 'F' 'F' 'M' 'F' 'M' 'M' 'F' 'F']\n",
      "[1 1 0 0 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "print y\n",
    "y= enc.fit_transform(y)\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7157078   0.          0.          0.          0.88371438]\n",
      " [ 0.          0.78553353  0.85010276  0.          0.        ]\n",
      " [ 0.          0.          0.76009782  0.7865069   0.        ]\n",
      " [ 0.          0.          0.          0.          0.89097667]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.8390625 ]\n",
      " [ 0.          0.          0.8000239   0.86039339  0.73899714]]\n",
      "[[ 0.7157078   0.78553353  0.80340816  0.82345014  0.88371438]\n",
      " [ 0.7157078   0.78553353  0.85010276  0.82345014  0.83818767]\n",
      " [ 0.7157078   0.78553353  0.76009782  0.7865069   0.83818767]\n",
      " [ 0.7157078   0.78553353  0.80340816  0.82345014  0.89097667]\n",
      " [ 0.7157078   0.78553353  0.80340816  0.82345014  0.83818767]\n",
      " [ 0.7157078   0.78553353  0.80340816  0.82345014  0.8390625 ]\n",
      " [ 0.7157078   0.78553353  0.8000239   0.86039339  0.73899714]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values = 0, strategy = \"mean\", axis = 0)\n",
    "\n",
    "print X_train\n",
    "print imp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.8390625 ]\n",
      " [ 0.          0.78553353  0.85010276  0.          0.        ]\n",
      " [ 0.97757077  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.8000239   0.86039339  0.73899714]\n",
      " [ 0.          0.          0.76009782  0.7865069   0.        ]\n",
      " [ 0.          0.          0.          0.          0.89097667]\n",
      " [ 0.910608    0.83239223  0.97092464  0.70809331  0.84331188]\n",
      " [ 0.7157078   0.          0.          0.          0.88371438]]\n",
      "[[ 1.          0.          0.         ...,  0.          0.          0.41588337]\n",
      " [ 1.          0.          0.78553353 ...,  0.          0.          0.        ]\n",
      " [ 1.          0.97757077  0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 1.          0.          0.         ...,  0.          0.          0.5614766 ]\n",
      " [ 1.          0.910608    0.83239223 ...,  0.30070845  0.3581322\n",
      "   0.42652166]\n",
      " [ 1.          0.7157078   0.         ...,  0.          0.          0.53896383]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(5)\n",
    "\n",
    "print X\n",
    "print poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "\n",
    "### Supervised Learning Estimators\n",
    "\n",
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel = \"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning Estimators\n",
    "\n",
    "#### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters = 3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "\n",
    "### Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the data\n",
    "print lr.fit(X, y)\n",
    "print knn.fit(X_train, y_train)\n",
    "print svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_means.fit(X_train) # fit the model to the data\n",
    "pca_model = pca.fit_transform(X_train) # Fit to data, then transform it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "### Supervised Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'M']\n",
      "[-0.0784857  -0.02429168  0.74195058]\n",
      "[[ 0.66666667  0.33333333]\n",
      " [ 0.66666667  0.33333333]\n",
      " [ 0.33333333  0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "print svc.predict(np.random.random((2, 5)))\n",
    "print lr.predict(X_test)\n",
    "print knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print k_means.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Your Model's Performance\n",
    "\n",
    "### Classification Metrics\n",
    "\n",
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'F' 'M']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print y_test\n",
    "y_pred = knn.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report\n",
    "\n",
    "Report ***precision***, ***recall***, ***f1-score***, and ***support***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          F       1.00      1.00      1.00         2\n",
      "          M       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       1.00      1.00      1.00         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressionn Metrics\n",
    "\n",
    "#### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, -0.5, 2] [-0.0784857  -0.02429168  0.74195058]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6040811487050055"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = lr.predict(X_test)\n",
    "y_true = [3, -0.5, 2]\n",
    "print y_true, y_pred\n",
    "mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7620203220190249"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R^2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.73631707170108851"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Metrics\n",
    "\n",
    "#### Adjusted Rand Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "adjusted_rand_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import homogeneity_score\n",
    "homogeneity_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import v_measure_score\n",
    "v_measure_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print cross_val_score(knn, X_train, y_train, cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Your Model\n",
    "\n",
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.285714285714\n",
      "1\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\"n_neighbors\": np.arange(1,3),\n",
    "              \"metric\": [\"euclidean\", \"cityblock\"]}\n",
    "grid = GridSearchCV(estimator=knn,\n",
    "                    param_grid=params)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.n_neighbors)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.571428571429\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
      "           weights='distance')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/XD/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "params = {\"n_neighbors\": range(1,5),\n",
    "          \"weights\": [\"uniform\", \"distance\"]}\n",
    "rsearch = RandomizedSearchCV(estimator=knn,\n",
    "                             param_distributions=params, cv=4,\n",
    "                             n_iter=8,\n",
    "                             random_state=5)\n",
    "rsearch.fit(X_train, y_train)\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
